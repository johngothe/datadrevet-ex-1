{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f6906958",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ed507e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "file = 'filtered_data.csv'\n",
        "df = pd.read_csv(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc47508f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"First 5 rows of the dataset:\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5aebc1a",
      "metadata": {},
      "source": [
        "Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3082ad1",
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41d1b1d",
      "metadata": {},
      "source": [
        "Datatypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8058d553",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af729b40",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.isnull().sum())\n",
        "# No null values but if there were a few we would drop them\n",
        "# df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b05a79c",
      "metadata": {},
      "source": [
        "# Outliers #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6bc0cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate and display outliers using IQR method for numerical columns\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "for col in numerical_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "    \n",
        "    print(f\"{col}:\")\n",
        "    print(f\"  Outlier count: {len(outliers)}\")\n",
        "    print(f\"  Outlier percentage: {len(outliers)/len(df)*100:.2f}%\")\n",
        "    print(f\"  Range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  Min outlier: {outliers[col].min():.2f}\")\n",
        "        print(f\"  Max outlier: {outliers[col].max():.2f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabab73b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations for outliers\n",
        "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(numerical_cols[:12]):  # Show first 12 numerical columns\n",
        "    # Calculate outlier bounds for this column\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    # Create box plot\n",
        "    sns.boxplot(data=df, y=col, ax=axes[i])\n",
        "    axes[i].set_title(f'{col} - Outliers Detection')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create additional plots for remaining numerical columns if any\n",
        "if len(numerical_cols) > 12:\n",
        "    remaining_cols = numerical_cols[12:]\n",
        "    n_remaining = len(remaining_cols)\n",
        "    n_cols = 4\n",
        "    n_rows = (n_remaining + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = [axes] if n_remaining == 1 else axes\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i, col in enumerate(remaining_cols):\n",
        "        sns.boxplot(data=df, y=col, ax=axes[i])\n",
        "        axes[i].set_title(f'{col} - Outliers Detection')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for j in range(i+1, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "148a64f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Variable groups from dataset documentation ---\n",
        "CONTINUOUS_VARS = [\n",
        "    \"age\", \"height\", \"weight\", \"sight_left\", \"sight_right\",\n",
        "    \"SBP\", \"DBP\", \"BLDS\", \"tot_chole\", \"HDL_chole\", \"LDL_chole\",\n",
        "    \"triglyceride\", \"hemoglobin\", \"serum_creatinine\",\n",
        "    \"SGOT_AST\", \"SGOT_ALT\", \"gamma_GTP\", \"waistline\"\n",
        "]\n",
        "\n",
        "ORDINAL_VARS = [\"urine_protein\"]  # exclude from IQR\n",
        "CATEGORICAL_VARS = [\"sex\", \"hear_left\", \"hear_right\", \"SMK_stat_type_cd\", \"DRK_YN\"]\n",
        "\n",
        "# Use intersection with actual columns\n",
        "cont_cols = [c for c in CONTINUOUS_VARS if c in df.columns]\n",
        "\n",
        "def iqr_bounds(s: pd.Series):\n",
        "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
        "    q1, q3 = s.quantile([0.25, 0.75])\n",
        "    iqr = q3 - q1\n",
        "    low = q1 - 1.5 * iqr\n",
        "    high = q3 + 1.5 * iqr\n",
        "    return low, high"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249c30ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove (clear errors)\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "REMOVE_RULES = {\n",
        "    \"waistline\": lambda s: s > 200,  # e.g., 1000 cm entries\n",
        "    \"serum_creatinine\": lambda s: s > 20,  # mg/dL, implausible highs\n",
        "    \"SGOT_AST\": lambda s: s > 9000,  # extreme enzyme typos\n",
        "    \"SGOT_ALT\": lambda s: s > 9000,\n",
        "    \"sight_left\": lambda s: s >= 5,  # 10.0 eyesight entries -> remove\n",
        "    \"sight_right\": lambda s: s >= 5,\n",
        "}\n",
        "\n",
        "# Apply removal rules\n",
        "mask_keep = pd.Series(True, index=df_clean.index)\n",
        "remove_report = []\n",
        "for col, rule in REMOVE_RULES.items():\n",
        "    if col in df_clean.columns:\n",
        "        bad = rule(pd.to_numeric(df_clean[col], errors=\"coerce\"))\n",
        "        n_bad = int(bad.sum())\n",
        "        if n_bad > 0:\n",
        "            mask_keep &= ~bad\n",
        "            remove_report.append((col, n_bad))\n",
        "\n",
        "df_clean = df_clean.loc[mask_keep]\n",
        "print(\"Rows removed (by column):\", remove_report)\n",
        "\n",
        "# =========================\n",
        "# 2) CAP (winsorize at IQR)\n",
        "# =========================\n",
        "cap_report = []\n",
        "for col in cont_cols:\n",
        "    if col in df_clean.columns:\n",
        "        low, high = iqr_bounds(df_clean[col])\n",
        "        before = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "        n_low = int((before < low).sum())\n",
        "        n_high = int((before > high).sum())\n",
        "        df_clean[col] = before.clip(lower=low, upper=high)\n",
        "        cap_report.append({\n",
        "            \"column\": col,\n",
        "            \"capped_low\": n_low,\n",
        "            \"capped_high\": n_high\n",
        "        })\n",
        "\n",
        "print(pd.DataFrame(cap_report))\n",
        "\n",
        "# ==============================\n",
        "# 3) TRANSFORM (reduce skew with log1p)\n",
        "# ==============================\n",
        "LOG1P_VARS = [\n",
        "    v for v in [\n",
        "        \"weight\", \"BLDS\", \"tot_chole\", \"HDL_chole\", \"LDL_chole\",\n",
        "        \"triglyceride\", \"SGOT_AST\", \"SGOT_ALT\", \"gamma_GTP\"\n",
        "    ]\n",
        "    if v in df_clean.columns\n",
        "]\n",
        "\n",
        "transform_report = []\n",
        "for col in LOG1P_VARS:\n",
        "    x = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "    n_neg = int((x < 0).sum())\n",
        "    if n_neg:\n",
        "        x = x.clip(lower=0)  # ensure non-negative before log1p\n",
        "    df_clean[col] = np.log1p(x)\n",
        "    transform_report.append({\n",
        "        \"column\": col,\n",
        "        \"negatives_clipped\": n_neg\n",
        "    })\n",
        "\n",
        "print(pd.DataFrame(transform_report))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fa0759",
      "metadata": {},
      "source": [
        "# Feature extracting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc25e9e",
      "metadata": {},
      "source": [
        "Feature extraction after stabilizing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ae9775c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derived features (feature extraction)\n",
        "df_clean['BMI'] = df_clean['weight'] / (df_clean['height'] / 100) ** 2\n",
        "df_clean['pulse_pressure'] = df_clean['SBP'] - df_clean['DBP']\n",
        "df_clean['LDL_to_HDL'] = df_clean['LDL_chole'] / df_clean['HDL_chole']\n",
        "df_clean['TG_to_HDL'] = df_clean['triglyceride'] / df_clean['HDL_chole']\n",
        "df_clean['sight_avg'] = (df_clean['sight_left'] + df_clean['sight_right']) / 2\n",
        "df_clean['hearing_avg'] = (df_clean['hear_left'] + df_clean['hear_right']) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1c7eb3",
      "metadata": {},
      "source": [
        "Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f7216e7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a copy to avoid changing the original dataset\n",
        "df_encoded = df_clean.copy()\n",
        "df_encoded.drop(columns=['hear_left','hear_right','sight_left','sight_right'], inplace=True)\n",
        "\n",
        "# Ordinal encoding: urine_protein (1 to 6 is ordered)\n",
        "df_encoded[\"urine_protein\"] = df_encoded[\"urine_protein\"].astype(int)\n",
        "\n",
        "# One-hot encoding for nominal variables\n",
        "nominal_vars = [\"sex\", \"SMK_stat_type_cd\", \"DRK_YN\"]\n",
        "\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=nominal_vars, drop_first=True)\n",
        "\n",
        "# Show only the newly created encoded columns\n",
        "encoded_cols = [col for col in df_encoded.columns if any(var in col for var in nominal_vars)] + [\"urine_protein\"]\n",
        "print(df_encoded[encoded_cols].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80fb1d5b",
      "metadata": {},
      "source": [
        "Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1caec157",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Summary statistics before scaling"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>waistline</th>\n",
              "      <th>SBP</th>\n",
              "      <th>triglyceride</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.0</td>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>49.52</td>\n",
              "      <td>4.14</td>\n",
              "      <td>81.2</td>\n",
              "      <td>122.33</td>\n",
              "      <td>4.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.01</td>\n",
              "      <td>0.18</td>\n",
              "      <td>9.1</td>\n",
              "      <td>13.89</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.00</td>\n",
              "      <td>3.51</td>\n",
              "      <td>57.0</td>\n",
              "      <td>83.50</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>45.00</td>\n",
              "      <td>4.03</td>\n",
              "      <td>75.0</td>\n",
              "      <td>112.00</td>\n",
              "      <td>4.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.00</td>\n",
              "      <td>4.11</td>\n",
              "      <td>81.0</td>\n",
              "      <td>121.00</td>\n",
              "      <td>4.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>55.00</td>\n",
              "      <td>4.26</td>\n",
              "      <td>87.0</td>\n",
              "      <td>131.00</td>\n",
              "      <td>5.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.00</td>\n",
              "      <td>4.54</td>\n",
              "      <td>105.0</td>\n",
              "      <td>159.50</td>\n",
              "      <td>5.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             age     weight  waistline        SBP  triglyceride\n",
              "count  592819.00  592819.00   592819.0  592819.00     592819.00\n",
              "mean       49.52       4.14       81.2     122.33          4.73\n",
              "std         7.01       0.18        9.1      13.89          0.53\n",
              "min        40.00       3.51       57.0      83.50          0.69\n",
              "25%        45.00       4.03       75.0     112.00          4.36\n",
              "50%        50.00       4.11       81.0     121.00          4.72\n",
              "75%        55.00       4.26       87.0     131.00          5.11\n",
              "max        60.00       4.54      105.0     159.50          5.70"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Summary statistics after standardization (Z-score)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>waistline</th>\n",
              "      <th>SBP</th>\n",
              "      <th>triglyceride</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "      <td>592819.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.36</td>\n",
              "      <td>-3.51</td>\n",
              "      <td>-2.66</td>\n",
              "      <td>-2.80</td>\n",
              "      <td>-7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.78</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.50</td>\n",
              "      <td>2.18</td>\n",
              "      <td>2.62</td>\n",
              "      <td>2.68</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             age     weight  waistline        SBP  triglyceride\n",
              "count  592819.00  592819.00  592819.00  592819.00     592819.00\n",
              "mean        0.00       0.00      -0.00      -0.00         -0.00\n",
              "std         1.00       1.00       1.00       1.00          1.00\n",
              "min        -1.36      -3.51      -2.66      -2.80         -7.64\n",
              "25%        -0.64      -0.66      -0.68      -0.74         -0.71\n",
              "50%         0.07      -0.19      -0.02      -0.10         -0.03\n",
              "75%         0.78       0.65       0.64       0.62          0.71\n",
              "max         1.50       2.18       2.62       2.68          1.82"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Columns to show\n",
        "cols_to_show = [\"age\", \"weight\", \"waistline\", \"SBP\", \"triglyceride\"]\n",
        "\n",
        "# Before scaling\n",
        "summary_before = df_encoded[cols_to_show].describe().round(2)\n",
        "\n",
        "# After scaling\n",
        "scaler = StandardScaler()\n",
        "df_scaled = df_encoded.copy()\n",
        "df_scaled[cols_to_show] = scaler.fit_transform(df_encoded[cols_to_show])\n",
        "summary_after = df_scaled[cols_to_show].describe().round(2)\n",
        "\n",
        "# Display summaries neatly in notebook\n",
        "display(Markdown(\"### Summary statistics before scaling\"))\n",
        "display(summary_before)\n",
        "\n",
        "display(Markdown(\"### Summary statistics after standardization (Z-score)\"))\n",
        "display(summary_after)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36808b0",
      "metadata": {},
      "source": [
        "Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd2e63a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set 'DRK_YN' (Drinker or Not) as target variable — use the encoded dataframe\n",
        "# If one-hot encoding created \"DRK_YN_Y\", use that as your target\n",
        "target_col = \"DRK_YN_Y\" if \"DRK_YN_Y\" in df_encoded.columns else \"DRK_YN\"\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df_encoded.drop(columns=[target_col])\n",
        "y = df_encoded[target_col]\n",
        "\n",
        "# Split the data into training and testing sets (80–20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training set shape (X_train):\", X_train.shape)\n",
        "print(\"Testing set shape (X_test):\", X_test.shape)\n",
        "print(\"Training set shape (y_train):\", y_train.shape)\n",
        "print(\"Testing set shape (y_test):\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd5df75",
      "metadata": {},
      "source": [
        "### Correlation filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5c1839",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Step 1 Correlation-based filtering ---\n",
        "corr_df = X_train.copy()\n",
        "corr_df['target'] = y_train\n",
        "\n",
        "corr_matrix = corr_df.corr(numeric_only=True)\n",
        "corr_with_target = corr_matrix['target'].drop('target').sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8,10))\n",
        "sns.barplot(x=corr_with_target.values, y=corr_with_target.index, palette=\"viridis\")\n",
        "plt.title(\"Feature correlations with alcohol consumption (train set)\")\n",
        "plt.xlabel(\"Correlation coefficient\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "selected_corr_features = corr_with_target[abs(corr_with_target) > 0.05].index.tolist()\n",
        "print(\"Kept after correlation filter:\", selected_corr_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea372a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- SAMPLE for faster feature selection ---\n",
        "# Use only 10–15% of data for RFE (same feature relationships, far less compute)\n",
        "X_sample = X_train.sample(frac=0.15, random_state=42)\n",
        "y_sample = y_train.loc[X_sample.index]\n",
        "\n",
        "# --- LIGHTER RandomForest for selection ---\n",
        "rf_estimator = RandomForestClassifier(\n",
        "    n_estimators=300,  # fewer trees = faster\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# --- RFE wrapper ---\n",
        "rfe = RFE(estimator=rf_estimator, n_features_to_select=10, step=1)\n",
        "rfe.fit(X_sample[selected_corr_features], y_sample)\n",
        "\n",
        "selected_features = X_sample[selected_corr_features].columns[rfe.support_].tolist()\n",
        "print(\"\\nFinal selected features by RFE:\\n\", selected_features)\n",
        "\n",
        "# --- Importance scores for selected features ---\n",
        "importance_scores = pd.Series(\n",
        "    rfe.estimator_.feature_importances_,\n",
        "    index=X_sample[selected_corr_features].columns[rfe.support_]\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=importance_scores.values, y=importance_scores.index, palette=\"magma\")\n",
        "plt.title(\"Feature Importance (Random Forest - RFE, sample subset)\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save selection for reproducibility\n",
        "pd.Series(selected_features, name=\"selected_features\").to_csv(\"selected_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d13012d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# Only train on selected features\n",
        "fast_models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "results_fast = []\n",
        "\n",
        "for name, model in fast_models.items():\n",
        "    model.fit(X_train[selected_features], y_train)\n",
        "    y_pred = model.predict(X_test[selected_features])\n",
        "    y_prob = model.predict_proba(X_test[selected_features])[:,1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
        "\n",
        "    results_fast.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"F1\": f1,\n",
        "        \"ROC-AUC\": auc\n",
        "    })\n",
        "\n",
        "results_fast_df = pd.DataFrame(results_fast).sort_values(by=\"F1\", ascending=False)\n",
        "print(results_fast_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafee135",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "slow_models = {\n",
        "    \"SVM (RBF Kernel)\": SVC(kernel='rbf', probability=True, gamma='scale', random_state=42),\n",
        "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=200, early_stopping=True, random_state=42)\n",
        "}\n",
        "\n",
        "# Optional: downsample for faster runs\n",
        "X_small = X_train[selected_features].sample(frac=0.1, random_state=42)\n",
        "y_small = y_train.loc[X_small.index]\n",
        "\n",
        "results_slow = []\n",
        "\n",
        "for name, model in slow_models.items():\n",
        "    model.fit(X_small, y_small)\n",
        "    y_pred = model.predict(X_test[selected_features])\n",
        "    y_prob = model.predict_proba(X_test[selected_features])[:,1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
        "\n",
        "    results_slow.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"F1\": f1,\n",
        "        \"ROC-AUC\": auc\n",
        "    })\n",
        "\n",
        "results_slow_df = pd.DataFrame(results_slow).sort_values(by=\"F1\", ascending=False)\n",
        "print(results_slow_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
